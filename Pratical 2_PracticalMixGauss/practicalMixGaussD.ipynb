{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import multivariate_normal\n",
    "import time\n",
    "import sys\n",
    "\n",
    "flt_min = sys.float_info.min\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA THINGS TO DO (Optional)\n",
    "1. Most of the code you have so far (both provided by us and probably coded by you) is filled with computationally inefficient for-loops. Vectorize the code such that these for loops are one/two-liners with matrix multiplications. This will greatly speed up your code. \n",
    "2. Use the mixtures of Gaussians model to classify the skin/non-skin data. You need to use the same training data and inference model you used in part A along with all the \n",
    "    functions you've completed in part C to perform MoG training on multi-dimensional data. \n",
    "3. Use the Gaussian model (with diagonal covariance) to classify\n",
    "face/non-face data (in FaceData.mat)\n",
    "4. Use the mixtures of Gaussians model (with diagonal covariance) to\n",
    "classify the face/non-face data\n",
    "5. Use the t-distribution instead of the normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the image\n",
    "im = plt.imread('bob_small.jpeg');\n",
    "#loading the segmentation mask\n",
    "gt = spio.loadmat('bob_GroundTruth_small.mat', squeeze_me=True)['gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the file\n",
    "trainingData = spio.loadmat('RGBSkinNonSkin.mat', squeeze_me=True)\n",
    "\n",
    "#extract the non-skin matrix\n",
    "RGBNonSkin = np.float32(trainingData['RGBNonSkin'])\n",
    "#extract the skin matrix\n",
    "RGBSkin = np.float32(trainingData['RGBSkin'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def getMixGaussLogLike(data, mixGaussEst): \n",
    "    \"\"\"\n",
    "    Calculate the log likelihood for the whole dataset under a mixture of Gaussians model.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data -- d by n matrix containing data points.\n",
    "    mixGaussEst -- dict containing the mixture of gaussians parameters.\n",
    "\n",
    "    Returns: \n",
    "    logLike -- scalar containing the log likelihood.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.atleast_2d(data)                                                                         \n",
    "    # find total number of data items                                                                  \n",
    "    nDims, nData = data.shape                                                                          \n",
    "    \n",
    "    # initialize log likelihoods                                                                       \n",
    "    logLike = 0;                                                                                       \n",
    "                                                                                                       \n",
    "    # run through each data item                                                                       \n",
    "    for cData in range(nData):                                                                         \n",
    "        thisData = data[:, cData]                                                                      \n",
    "        # TO DO - calculate likelihood of this data point under mixture of                         \n",
    "        # Gaussians model. Replace this                                                                \n",
    "        like = 0\n",
    "        for k in range(mixGaussEst['k']):\n",
    "            weight = mixGaussEst['weight'][k]\n",
    "            mu = mixGaussEst['mean'][:, k]\n",
    "            cov = mixGaussEst['cov'][:,:,k]\n",
    "            prob = (1 / ((2*np.pi)**(nDims/2) * np.sqrt(np.linalg.det(cov))) * \n",
    "                    np.exp(-0.5 * (thisData - mu).T @ np.linalg.inv(cov) @ (thisData - mu)))\n",
    "            like += weight * prob\n",
    "        \n",
    "        # add to total log like                                                                        \n",
    "        logLike = logLike + np.log(like)                                                               \n",
    "                                                                                                       \n",
    "    return  logLike.item()                                                                       \n",
    "                                                                                                       "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fitMixGauss(data, k):\n",
    "    \"\"\"\n",
    "    Estimate a k MoG model that would fit the data. Incremently plots the outcome.\n",
    "               \n",
    "    \n",
    "    Keyword arguments:\n",
    "    data -- d by n matrix containing data points.\n",
    "    k -- scalar representing the number of gaussians to use in the MoG model.\n",
    "    \n",
    "    Returns: \n",
    "    mixGaussEst -- dict containing the estimated MoG parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #     MAIN E-M ROUTINE  \n",
    "    #     In the E-M algorithm, we calculate a complete posterior distribution over                                  \n",
    "    #     the (nData) hidden variables in the E-Step.  \n",
    "    #     In the M-Step, we update the parameters of the Gaussians (mean, cov, w).   \n",
    "\n",
    "    nDims, nData = data.shape\n",
    "\n",
    "    postHidden = np.zeros(shape=(k, nData))\n",
    "\n",
    "    # we will initialize the values to random values\n",
    "    mixGaussEst = dict()\n",
    "    mixGaussEst['d'] = nDims\n",
    "    mixGaussEst['k'] = k\n",
    "    mixGaussEst['weight'] = (1 / k) * np.ones(shape=(k))\n",
    "    mixGaussEst['mean'] = 2 * np.random.randn(nDims, k)\n",
    "    mixGaussEst['cov'] = np.random.randn(nDims, nDims, k)\n",
    "    for cGauss in range(k):\n",
    "        mixGaussEst['cov'][:, :, cGauss] = 2.5 + 1.5 * np.random.uniform() * np.eye(nDims)\n",
    "\n",
    "    # calculate current likelihood\n",
    "    # TO DO - fill in this routine\n",
    "    logLike = getMixGaussLogLike(data, mixGaussEst)\n",
    "    print('Log Likelihood Iter 0 : {:4.3f}\\n'.format(logLike))\n",
    "\n",
    "    nIter = 30;\n",
    "\n",
    "    logLikeVec = np.zeros(shape=(2 * nIter))\n",
    "    boundVec = np.zeros(shape=(2 * nIter))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    for cIter in range(nIter):\n",
    "\n",
    "        # ===================== =====================\n",
    "        # Expectation step\n",
    "        # ===================== =====================\n",
    "\n",
    "        for cData in range(nData):\n",
    "            # TO DO (g) : fill in column of 'hidden' - calculate posterior probability that\n",
    "            # this data point came from each of the Gaussians\n",
    "            # replace this:\n",
    "            thisData = data[:, cData]\n",
    "            l = np.zeros((k, nData))\n",
    "            for i in range(k):\n",
    "                weight = mixGaussEst['weight'][i]\n",
    "                mu = mixGaussEst['mean'][:, i]\n",
    "                cov = mixGaussEst['cov'][:, :, i]\n",
    "                prob = (1 / ((2 * np.pi) ** (nData / 2) * np.sqrt(np.linalg.det(cov))) *\n",
    "                        np.exp(-0.5 * (thisData - mu).T @ np.linalg.inv(cov) @ (thisData - mu)))\n",
    "                l[i] = weight * prob\n",
    "            postHidden[:, cData] = l[:, cData] / np.sum(l[:, cData])\n",
    "\n",
    "        # ===================== =====================\n",
    "        # Maximization Step\n",
    "        # ===================== =====================\n",
    "        # for each constituent Gaussian\n",
    "        for cGauss in range(k):\n",
    "            # TO DO (h):  Update weighting parameters mixGauss.weight based on the total\n",
    "            # posterior probability associated with each Gaussian. Replace this:\n",
    "            mixGaussEst['weight'][cGauss] = np.sum(postHidden[cGauss, :]) / np.sum(postHidden)\n",
    "\n",
    "            # TO DO (i):  Update mean parameters mixGauss.mean by weighted average\n",
    "            # where weights are given by posterior probability associated with\n",
    "            # Gaussian.  Replace this:\n",
    "            tmp = 0\n",
    "            for i in range(nData):\n",
    "                tmp += postHidden[cGauss, i] * data[:, i]\n",
    "            mixGaussEst['mean'][:, cGauss] = tmp / np.sum(postHidden[cGauss, :])\n",
    "\n",
    "            # TO DO (j):  Update covarance parameter based on weighted average of\n",
    "            # square distance from update mean, where weights are given by\n",
    "            # posterior probability associated with Gaussian\n",
    "            tmp = 0\n",
    "            for i in range(nData):\n",
    "                tmp += (postHidden[cGauss, i] * (data[:, i] - mixGaussEst['mean'][:, cGauss]).reshape(-1, 1) @ (\n",
    "                            data[:, i] - mixGaussEst['mean'][:, cGauss]).reshape(1, -1))\n",
    "            mixGaussEst['cov'][:, :, cGauss] = tmp / np.sum(postHidden[cGauss, :])\n",
    "\n",
    "            # draw the new solution\n",
    "\n",
    "        drawEMData2d(data, mixGaussEst)\n",
    "        time.sleep(0.7)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # calculate the log likelihood\n",
    "        logLike = getMixGaussLogLike(data, mixGaussEst)\n",
    "        print('Log Likelihood After Iter {} : {:4.3f}\\n'.format(cIter, logLike))\n",
    "\n",
    "    return mixGaussEst"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
